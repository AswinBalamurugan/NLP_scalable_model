{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>response_1</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>response_2</td>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_3</td>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>response_4</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_5</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response_id        class                                      response_text  \\\n",
       "0  response_1  not_flagged              I try and avoid this sort of conflict   \n",
       "1  response_2      flagged  Had a friend open up to me about his mental ad...   \n",
       "2  response_3      flagged  I saved a girl from suicide once. She was goin...   \n",
       "3  response_4  not_flagged  i cant think of one really...i think i may hav...   \n",
       "4  response_5  not_flagged  Only really one friend who doesn't fit into th...   \n",
       "\n",
       "  Unnamed: 3  Unnamed: 4 Unnamed: 5  Unnamed: 6 Unnamed: 7  \n",
       "0        NaN         NaN        NaN         NaN        NaN  \n",
       "1        NaN         NaN        NaN         NaN        NaN  \n",
       "2        NaN         NaN        NaN         NaN        NaN  \n",
       "3        NaN         NaN        NaN         NaN        NaN  \n",
       "4                    NaN        NaN         NaN        NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Sheet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class            0\n",
      "response_text    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                      response_text\n",
       "0  not_flagged              I try and avoid this sort of conflict\n",
       "1      flagged  Had a friend open up to me about his mental ad...\n",
       "2      flagged  I saved a girl from suicide once. She was goin...\n",
       "3  not_flagged  i cant think of one really...i think i may hav...\n",
       "4  not_flagged  Only really one friend who doesn't fit into th..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df['class'],df['response_text']],axis=1)\n",
    "print(df.isnull().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                      response_text\n",
       "0      0              I try and avoid this sort of conflict\n",
       "1      1  Had a friend open up to me about his mental ad...\n",
       "2      1  I saved a girl from suicide once. She was goin...\n",
       "3      0  i cant think of one really...i think i may hav...\n",
       "4      0  Only really one friend who doesn't fit into th..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = df['class'].replace({'not_flagged':0,'flagged':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/aswin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/aswin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/aswin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nlp\n",
    "\n",
    "processed_sentences = []\n",
    "for sentence in df['response_text']:\n",
    "    \n",
    "    # removing non-letter symbols and then lowercasing the letters\n",
    "    sentence = re.sub(\"[^a-zA-Z]\",\" \",sentence)\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # splitting the sentence to words using tokenize and then filtering out the stopwords\n",
    "    sentence = nltk.word_tokenize(sentence)\n",
    "    sentence = [word for word in sentence if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    # using lemmatizer to convert the words to their base form and then joining the words to get back the sentence\n",
    "    lemm = nlp.WordNetLemmatizer()\n",
    "    sentence = ' '.join([lemm.lemmatize(word) for word in sentence])\n",
    "\n",
    "    processed_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequently used 500 words ['able', 'absolutely', 'acquaintance', 'acted', 'action', 'activity', 'addiction', 'adequate', 'admit', 'advice', 'advise', 'age', 'ago', 'agony', 'alcoholic', 'allowed', 'anniversary', 'answer', 'anxiety', 'anxious', 'apposed', 'ask', 'asks', 'attention', 'aunt', 'avoid', 'away', 'bad', 'basically', 'bedroom', 'best', 'better', 'big', 'bit', 'blow', 'blue', 'blunt', 'book', 'boyfriend', 'break', 'bring', 'brother', 'brought', 'bunch', 'called', 'calling', 'calm', 'came', 'camp', 'camping', 'campsite', 'cancer', 'car', 'care', 'caring', 'category', 'caught', 'cause', 'chance', 'change', 'changed', 'chat', 'circumstance', 'clean', 'cleaning', 'cocaine', 'come', 'comfort', 'comforted', 'commit', 'common', 'complete', 'completely', 'concern', 'confines', 'conflict', 'convinced', 'cop', 'cope', 'counselor', 'countless', 'couple', 'crazy', 'cutter', 'cutting', 'damn', 'dating', 'day', 'dealing', 'dealt', 'death', 'defined', 'depressed', 'depression', 'describes', 'desire', 'diagnosed', 'dialog', 'difficulty', 'disorder', 'doc', 'dont', 'douche', 'drag', 'drove', 'drug', 'dump', 'dumped', 'dying', 'ear', 'earlier', 'email', 'emotional', 'encourage', 'end', 'ended', 'entire', 'essential', 'esteem', 'eventually', 'everyday', 'ex', 'example', 'excited', 'experience', 'express', 'expressing', 'extremely', 'face', 'facebook', 'faced', 'facing', 'fact', 'fairly', 'family', 'father', 'feel', 'feeling', 'fell', 'felt', 'fight', 'fit', 'fixed', 'flicker', 'focus', 'friend', 'frustrated', 'gave', 'ged', 'gf', 'girl', 'girlfriend', 'giving', 'goal', 'going', 'gone', 'good', 'got', 'grade', 'grandmother', 'guess', 'guy', 'hadnt', 'haha', 'half', 'hand', 'happens', 'hard', 'harmed', 'head', 'healing', 'health', 'hear', 'heard', 'help', 'helped', 'helpful', 'helping', 'hesitate', 'high', 'hit', 'hold', 'home', 'homeless', 'honest', 'hood', 'hope', 'hoping', 'horrable', 'hospital', 'hour', 'house', 'huge', 'human', 'hung', 'hurt', 'idk', 'important', 'indirectly', 'ing', 'initiated', 'innermost', 'input', 'inside', 'intense', 'internet', 'irl', 'isolated', 'issue', 'jokingly', 'judge', 'junior', 'kid', 'kill', 'killed', 'kind', 'kindness', 'knew', 'know', 'knowledge', 'known', 'lack', 'late', 'laugh', 'le', 'lent', 'let', 'letting', 'level', 'life', 'light', 'like', 'line', 'listen', 'listened', 'listener', 'listening', 'little', 'living', 'logical', 'long', 'look', 'looked', 'losing', 'loss', 'lost', 'lot', 'loving', 'low', 'major', 'make', 'making', 'managed', 'maybe', 'memorial', 'men', 'mental', 'met', 'method', 'mind', 'mom', 'month', 'mother', 'mt', 'nah', 'naturally', 'necessarily', 'need', 'needed', 'nervous', 'nice', 'night', 'normal', 'number', 'objective', 'obtain', 'occurrence', 'od', 'offer', 'offered', 'oh', 'ok', 'open', 'openness', 'overcome', 'packed', 'parent', 'past', 'path', 'peace', 'people', 'perfect', 'period', 'person', 'personal', 'physical', 'picked', 'pill', 'positive', 'possible', 'possibly', 'pretty', 'probably', 'problem', 'progress', 'promised', 'provide', 'psych', 'pulled', 'purpose', 'qualified', 'question', 'quite', 'rant', 'rational', 'reading', 'reality', 'realize', 'really', 'recovery', 'refers', 'reflect', 'rehab', 'rejected', 'rejecting', 'relate', 'related', 'relationship', 'relief', 'remember', 'remind', 'remote', 'resource', 'respect', 'restless', 'result', 'roommate', 'rude', 'sad', 'said', 'saved', 'saw', 'say', 'saying', 'school', 'schoolwork', 'self', 'sense', 'set', 'severe', 'share', 'shared', 'sharing', 'shelter', 'shit', 'shortly', 'sign', 'similar', 'simply', 'sister', 'situation', 'skipped', 'slightly', 'slowly', 'somebody', 'sort', 'speak', 'specific', 'specifically', 'spent', 'spiraling', 'spot', 'stability', 'start', 'started', 'stayed', 'stopped', 'story', 'stranger', 'struggle', 'struggling', 'stuff', 'subject', 'suffer', 'suicidal', 'suicide', 'summer', 'super', 'support', 'supporting', 'supportive', 'sure', 'surfing', 'survival', 'sustained', 'swallow', 'swaying', 'swimming', 'switch', 'switched', 'taken', 'taking', 'talk', 'talked', 'talking', 'teacher', 'tell', 'telling', 'thankgiving', 'thats', 'therapist', 'therapy', 'theripist', 'thing', 'think', 'thinking', 'thought', 'threw', 'till', 'time', 'told', 'took', 'tough', 'trapped', 'treat', 'treatment', 'tried', 'trouble', 'troubled', 'truth', 'try', 'tryin', 'trying', 'tunnel', 'turmoil', 'tutor', 'twice', 'type', 'understand', 'unfortunately', 'unless', 'used', 'using', 'vent', 'verge', 'virgity', 'visited', 'walked', 'want', 'wanted', 'ward', 'way', 'weed', 'week', 'went', 'wood', 'work', 'worked', 'write', 'year', 'yearbook']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "max_feature = 500\n",
    "\n",
    "cv = CountVectorizer(max_features=max_feature, stop_words='english')\n",
    "matrix = cv.fit_transform(processed_sentences).toarray()\n",
    "\n",
    "print(\"Most frequently used {} words {}\".format(max_feature, cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matrix\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "[0 1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(X,'\\n')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.890625\n",
      "Test Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False,eval_metric='error').fit(X_train,y_train)\n",
    "\n",
    "pred_xgb_train = xgb.predict(X_train)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "print('Train Accuracy: ',accuracy_score(y_train,pred_xgb_train))\n",
    "print('Test Accuracy: ',accuracy_score(y_test,pred_xgb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b4ada098d133e6ba3690b75a455668b4b88820b75d97973ca15abfc2b612c9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
